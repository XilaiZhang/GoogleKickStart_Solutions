the last round of 2021, the next round will be many months later... <br />
transformTheString.py: try forward and backword direction for each char. <br /><br />
painter.py: track line segments for each primary color, break for each segment. <br /><br />
sillySubstitution.py: The key observation is that we can break the possible positions for replacement into 10 parallel separate replacements. i.e., replacemnt of 01, 12, 23 ... 90. And when we are considering each replacement, it could only affect replacement positions in a different set. e.g. if we replace 12 at position x, then this will turn into a number 3, which could only form possible future replacements of 23 at position x-1 or of 34 at position x, which is separate from the remaining replacement of 12 and means that we can continue with all replacements of remaining 12s safely. With that being said, we use 10 sets to track the possible replacement positions of 01, 12... 90. In each iteration, we iterate over all 10 sets. When we replace a sequence (x)(x+1), we update the possible positions in the (x+1)(x+2) set and (x+2)(x+3) set, and continue with our replacements of x(x+1). Since we can do at most N replacements, and each replacement bring up at most 2 positions, the total run time is bounded by 2\*N. <br /><br />
dependentEvents.cpp: We use the same set of formulas as provided in the official analysis. Besides the formulas, based on the output requirement and to save computation time, for each intermediate fraction of the form p / 1e6, we turn it into p * inverse(1e6) mod (1e9 +7 ). And the inverse of 1e6 can be pre-computed as well, so that we can use it as a constant. Now, to leverage on the core binary lifting algorithm, besides using it to find the parents, we also use it to binary lift probabilities. <br />
I give my variables long names in the hope that they become self explanatory in explaining how we binary lift probabilites. In code, we use prob\[u]\[v] as a structure to store all the probabilities. Now, we are interested in how the probabilities of the 2^v th ancestor of u would affect u. In the code, the prob\[u]\[v].ancestorHappenMeHappen variable stores the probability of u happen given u's 2^v th ancestor happen. The variable names are named similarly for prob\[u]\[v].ancestorNotHappenMeHappen, prob\[u]\[v].ancestorNotHappenMeNotHappen etc. Based on probability formulas, we can chain our probabilities together. Namely, since p ( x | y ) = p (x | z ) \* p (z | y), we can reach from u to its ancestor of ancestor, and therefore ancestor of ancestor of ancestor and so on... For example, to compute prob\[x]\[y].ancestorHappenMeHappen, we can add together (1) prob\[x]\[z].ancestorHappenMeHappen \* prob\[z]\[y].ancestorHappenMeHappen, and (2) prob\[x]\[z].ancestorNotHappenMeHappen \* prob\[z]\[y].ancestorHappenMeNotHappen. In other words, the probability of x happen given y is the same as the sum of (1) (probability of x happen given z happen) times (probability of z happen given y happen), and (2) (probability of x happen given z not happen) times (probability of z not happen given y happen). All four variables for each prob structure can be computed similarly. <br />

Using the above mentioned chain rules, we can binary lift and store all p(u | A ) for each node u, where all the (A) are u's 2^x th ancestor. Suppose v is u's some random ancestor, We can therefore compute the probability from point v to u, by breaking the distance of (v-u) into exponentials of 2. For example, if the ancestor v that we are interested in, is 7 levels above u, we can chain the probabilities this way: We first chain probability of u with (its ancestor 4 levels above), let’s call this ancestor V1. And then we chain V1 with (V1’s ancestor 2 levels above), and let’s call this ancestor V2. And finally we chain with V2’s ancestor 1 level above, v. And indeed if we reach from u to V1 to V2 to v, the total amount of levels we reached is 4+2+1=7 levels, which is the level difference between u and v. And what’s more, p(u|v) can be computed by chaining p(u|V1), p(V1 | V2) and p(V2 | v), which only take 3 steps. (the method of chaining is exaplined in the paragraph above) In general, we can compute probability of u from its ancestors N levels above, in log N steps. With the probability information, for each query (x,y), and their lowest common ancestor a, we can retrieve the probability information of p(x | a), p (y | a), p(a | root) and then plug these values into the formula as outlined in the official analysis. The propagation of binary lifting is N log N complexity. And for each query, we reach up for at most log N steps. Thus we answer all queries in Q \* log N complexity. The overall complexity is therefore N log N + Q log N. 
